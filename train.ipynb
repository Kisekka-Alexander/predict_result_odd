{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('premier_league_result_odds.csv')\n",
    "# Calculate implied probabilities\n",
    "data['home_implied'] = 1 / data['home_odds']\n",
    "data['draw_implied'] = 1 / data['draw_odds']\n",
    "data['away_implied'] = 1 / data['away_odds']\n",
    "\n",
    "# Calculate bookmaker margin (overround)\n",
    "data['overround'] = data['home_implied'] + data['draw_implied'] + data['away_implied'] - 1\n",
    "\n",
    "# Calculate true probabilities (normalized)\n",
    "data['home_prob'] = data['home_implied'] / (1 + data['overround'])\n",
    "data['draw_prob'] = data['draw_implied'] / (1 + data['overround'])\n",
    "data['away_prob'] = data['away_implied'] / (1 + data['overround'])\n",
    "\n",
    "\n",
    "# # Calculate value indicators\n",
    "# data['home_value'] = data['home_prob'] - data['home_implied']\n",
    "# data['away_value'] = data['away_prob'] - data['away_implied']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins globally (or at least at same scope level as both functions)\n",
    "ODDS_BINS = [1, 1.5, 2, 2.5, 3, 4, 5, 10, float('inf')]\n",
    "ODDS_LABELS = [f\"{ODDS_BINS[i]}-{ODDS_BINS[i+1]}\" for i in range(len(ODDS_BINS)-1)]\n",
    "\n",
    "def precompute_team_performance(data):\n",
    "    team_features = {}\n",
    "    \n",
    "    for team in set(data['home_team']).union(set(data['away_team'])):\n",
    "        team_matches = data[(data['home_team'] == team) | (data['away_team'] == team)]\n",
    "        \n",
    "        # Home performance\n",
    "        home_perf = team_matches[team_matches['home_team'] == team].copy()\n",
    "        home_perf['odds_bin'] = pd.cut(home_perf['home_odds'], \n",
    "                                     bins=ODDS_BINS,\n",
    "                                     labels=ODDS_LABELS)\n",
    "        home_win_rate = home_perf.groupby('odds_bin')['winning_outcome'].apply(\n",
    "            lambda x: (x == 'Home').mean()\n",
    "        ).to_dict()\n",
    "        \n",
    "        # Away performance\n",
    "        away_perf = team_matches[team_matches['away_team'] == team].copy()\n",
    "        away_perf['odds_bin'] = pd.cut(away_perf['away_odds'], \n",
    "                                     bins=ODDS_BINS,\n",
    "                                     labels=ODDS_LABELS)\n",
    "        away_win_rate = away_perf.groupby('odds_bin')['winning_outcome'].apply(\n",
    "            lambda x: (x == 'Away').mean()\n",
    "        ).to_dict()\n",
    "        \n",
    "        team_features[team] = {\n",
    "            'home_win_rates': home_win_rate,\n",
    "            'away_win_rates': away_win_rate\n",
    "        }\n",
    "    \n",
    "    return team_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute once (save this object)\n",
    "team_performance = precompute_team_performance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_feature(row):\n",
    "    home_team = row['home_team']\n",
    "    away_team = row['away_team']\n",
    "    home_odd = row['home_odds']\n",
    "    away_odd = row['away_odds']\n",
    "    \n",
    "    # Find which bin the current odds falls into\n",
    "    def find_bin(odds):\n",
    "        for i in range(len(ODDS_BINS)-1):\n",
    "            if ODDS_BINS[i] <= odds < ODDS_BINS[i+1]:\n",
    "                return ODDS_LABELS[i]\n",
    "        return ODDS_LABELS[-1]  # default to last bin\n",
    "    \n",
    "    home_bin = find_bin(home_odd)\n",
    "    away_bin = find_bin(away_odd)\n",
    "    \n",
    "    return pd.Series({\n",
    "        'home_win_rate': team_performance[home_team]['home_win_rates'].get(home_bin, 0.5),\n",
    "        'away_win_rate': team_performance[away_team]['away_win_rates'].get(away_bin, 0.3)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply to dataframe\n",
    "data[['home_win_rate', 'away_win_rate']] = data.apply(get_performance_feature, axis=1)\n",
    "\n",
    "# Create odds-based features only\n",
    "X = data[['home_odds', 'draw_odds', 'away_odds', \n",
    "        'home_prob', 'draw_prob', 'away_prob',\n",
    "        'overround',\n",
    "        'home_win_rate', 'away_win_rate']]\n",
    "y = data['winning_outcome']\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model\n",
    "model = GradientBoostingClassifier(n_estimators=200, max_depth=4)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_rate(team, is_home, odds):\n",
    "    \"\"\"Helper function to lookup team performance at given odds\"\"\"\n",
    "    # Find which bin these odds fall into\n",
    "    for i in range(len(ODDS_BINS)-1):\n",
    "        if ODDS_BINS[i] <= odds < ODDS_BINS[i+1]:\n",
    "            bin_label = ODDS_LABELS[i]\n",
    "            break\n",
    "    else:\n",
    "        bin_label = ODDS_LABELS[-1]  # default to last bin\n",
    "    \n",
    "    # Get the appropriate win rates dictionary\n",
    "    rates_dict = team_performance[team]['home_win_rates' if is_home else 'away_win_rates']\n",
    "    return rates_dict.get(bin_label, 0.5 if is_home else 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prediction function for new matches\n",
    "def predict_match(home_team, away_team, home_odds, draw_odds, away_odds):\n",
    "    # Calculate basic odds features\n",
    "    home_implied = 1 / home_odds\n",
    "    draw_implied = 1 / draw_odds\n",
    "    away_implied = 1 / away_odds\n",
    "    overround = (home_implied + draw_implied + away_implied) - 1\n",
    "    home_prob = home_implied / (1 + overround)\n",
    "    draw_prob = draw_implied / (1 + overround)\n",
    "    away_prob = away_implied / (1 + overround)\n",
    "    \n",
    "    home_win_rate = get_win_rate(home_team, True, home_odds)\n",
    "    away_win_rate = get_win_rate(away_team, False, away_odds)\n",
    "    \n",
    "    # Create feature array IN THE EXACT ORDER USED IN TRAINING\n",
    "    features = [\n",
    "        home_odds, draw_odds, away_odds,\n",
    "        home_prob, draw_prob, away_prob,\n",
    "        overround,\n",
    "        home_win_rate, away_win_rate\n",
    "    ]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict([features])[0]\n",
    "    probabilities = model.predict_proba([features])[0]\n",
    "    \n",
    "    return prediction, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "home_team = \"Liverpool\"\n",
    "away_team = \"Bournemouth\"\n",
    "home_odds = 1.38\n",
    "draw_odds = 5.23\n",
    "away_odds = 6.96\n",
    "prediction, probs = predict_match(home_team, away_team, home_odds, draw_odds, away_odds)\n",
    "print(f\"Predicted outcome: {prediction}\")\n",
    "print(f\"Probabilities: Home={probs[0]:.2f}, Draw={probs[1]:.2f}, Away={probs[2]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify the minimum odds among 'Home', 'Away', and 'Draw'\n",
    "# data['min_odd'] = data[['Home', 'Away', 'Draw']].min(axis=1)\n",
    "\n",
    "# # Count the occurrences of each result for the minimum odds\n",
    "# result_counts = data.groupby('min_odd')['Result'].value_counts().fillna(0)\n",
    "\n",
    "# # print(result_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train SVM\n",
    "# model = SVC()\n",
    "# model.fit(X_train, y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# test_odds = [[3.28,3.38,2.3]]\n",
    "# test_pred = model.predict(test_odds)\n",
    "\n",
    "# # Evaluate the model\n",
    "# cross_val_accuracy = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "# conf_matrix = confusion_matrix(y_test, predictions)\n",
    "# class_report = classification_report(y_test, predictions)\n",
    "# print(test_pred)\n",
    "# print(f'Cross-Validation Accuracy: {cross_val_accuracy.mean()}')\n",
    "# print(conf_matrix)\n",
    "# print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Implement GridSearch\n",
    "# param_grid = {\"C\": [0.1,1,10,100], \"gamma\": [1,0.1,0.01,0.001]}\n",
    "# grid = GridSearchCV(SVC(), param_grid, verbose=3)\n",
    "# grid.fit(X_train, y_train)\n",
    "# grid_prediction = grid.predict(X_test)\n",
    "# conf_matrix = confusion_matrix(y_test, grid_prediction)\n",
    "# print(conf_matrix)\n",
    "# class_report = classification_report(y_test, grid_prediction)\n",
    "# print(f'Cross-Validation Accuracy: {cross_val_accuracy.mean()}')\n",
    "# print(classification_report(y_test, grid_prediction))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
