{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c53cb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dc7d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('premier_league_result_odds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0bcd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_features(data):\n",
    "    \"\"\"Create more sophisticated features for better prediction\"\"\"\n",
    "    \n",
    "    # Basic implied probability features (your existing code)\n",
    "    data['home_implied'] = 1 / data['home_odds']\n",
    "    data['draw_implied'] = 1 / data['draw_odds']\n",
    "    data['away_implied'] = 1 / data['away_odds']\n",
    "    data['overround'] = data['home_implied'] + data['draw_implied'] + data['away_implied'] - 1\n",
    "    data['home_prob'] = data['home_implied'] / (1 + data['overround'])\n",
    "    data['draw_prob'] = data['draw_implied'] / (1 + data['overround'])\n",
    "    data['away_prob'] = data['away_implied'] / (1 + data['overround'])\n",
    "    \n",
    "    # NEW ADVANCED FEATURES\n",
    "    \n",
    "    # 1. Odds ratios and spreads\n",
    "    data['home_away_odds_ratio'] = data['home_odds'] / data['away_odds']\n",
    "    data['odds_spread'] = data['home_odds'].abs() - data['away_odds'].abs()\n",
    "    data['favorite_odds'] = data[['home_odds', 'away_odds']].min(axis=1)\n",
    "    data['underdog_odds'] = data[['home_odds', 'away_odds']].max(axis=1)\n",
    "    data['odds_variance'] = data[['home_odds', 'draw_odds', 'away_odds']].var(axis=1)\n",
    "    \n",
    "    # 2. Market confidence indicators\n",
    "    data['market_confidence'] = 1 / data['overround']  # Lower overround = higher confidence\n",
    "    data['draw_bias'] = data['draw_prob'] - 0.33  # How much market favors draw vs uniform\n",
    "    data['home_advantage'] = data['home_prob'] - data['away_prob']\n",
    "    \n",
    "    # 3. Categorical odds ranges\n",
    "    data['home_odds_category'] = pd.cut(data['home_odds'], \n",
    "                                       bins=[0, 1.5, 2.5, 4.0, float('inf')],\n",
    "                                       labels=['Heavy_Favorite', 'Favorite', 'Slight_Favorite', 'Underdog'])\n",
    "    data['away_odds_category'] = pd.cut(data['away_odds'], \n",
    "                                       bins=[0, 1.5, 2.5, 4.0, float('inf')],\n",
    "                                       labels=['Heavy_Favorite', 'Favorite', 'Slight_Favorite', 'Underdog'])\n",
    "    \n",
    "    # 4. Match competitiveness\n",
    "    data['match_competitiveness'] = 1 / (abs(data['home_prob'] - data['away_prob']) + 0.01)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14e5d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_advanced_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fec3f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_team_performance(data):\n",
    "    \"\"\"Calculate more detailed team performance metrics\"\"\"\n",
    "    team_stats = {}\n",
    "    \n",
    "    for team in set(data['home_team']).union(set(data['away_team'])):\n",
    "        # Home performance\n",
    "        home_matches = data[data['home_team'] == team]\n",
    "        home_wins = len(home_matches[home_matches['winning_outcome'] == 'Home'])\n",
    "        home_total = len(home_matches)\n",
    "        \n",
    "        # Away performance  \n",
    "        away_matches = data[data['away_team'] == team]\n",
    "        away_wins = len(away_matches[away_matches['winning_outcome'] == 'Away'])\n",
    "        away_total = len(away_matches)\n",
    "        \n",
    "        # Overall performance\n",
    "        total_matches = home_total + away_total\n",
    "        total_wins = home_wins + away_wins\n",
    "        draws = len(data[((data['home_team'] == team) | (data['away_team'] == team)) & \n",
    "                         (data['winning_outcome'] == 'Draw')])\n",
    "        \n",
    "        # Performance by odds ranges\n",
    "        home_fav_wins = len(home_matches[(home_matches['home_odds'] < 2.0) & \n",
    "                                        (home_matches['winning_outcome'] == 'Home')])\n",
    "        home_fav_total = len(home_matches[home_matches['home_odds'] < 2.0])\n",
    "        \n",
    "        away_fav_wins = len(away_matches[(away_matches['away_odds'] < 2.0) & \n",
    "                                        (away_matches['winning_outcome'] == 'Away')])\n",
    "        away_fav_total = len(away_matches[away_matches['away_odds'] < 2.0])\n",
    "        \n",
    "        team_stats[team] = {\n",
    "            'home_win_rate': home_wins / max(home_total, 1),\n",
    "            'away_win_rate': away_wins / max(away_total, 1),\n",
    "            'overall_win_rate': total_wins / max(total_matches, 1),\n",
    "            'draw_rate': draws / max(total_matches, 1),\n",
    "            'home_fav_win_rate': home_fav_wins / max(home_fav_total, 1),\n",
    "            'away_fav_win_rate': away_fav_wins / max(away_fav_total, 1),\n",
    "            'total_matches': total_matches\n",
    "        }\n",
    "    \n",
    "    return team_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7196c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = enhanced_team_performance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "807767a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_team_features(data, team_stats):\n",
    "    \"\"\"Add team-specific features to the dataset\"\"\"\n",
    "    \n",
    "    def get_team_features(row):\n",
    "        home_team = row['home_team']\n",
    "        away_team = row['away_team']\n",
    "        \n",
    "        home_stats = team_stats.get(home_team, {})\n",
    "        away_stats = team_stats.get(away_team, {})\n",
    "        \n",
    "        return pd.Series({\n",
    "            'home_team_win_rate': home_stats.get('home_win_rate', 0.5),\n",
    "            'away_team_win_rate': away_stats.get('away_win_rate', 0.3),\n",
    "            'home_team_overall_rate': home_stats.get('overall_win_rate', 0.4),\n",
    "            'away_team_overall_rate': away_stats.get('overall_win_rate', 0.4),\n",
    "            'home_team_draw_rate': home_stats.get('draw_rate', 0.3),\n",
    "            'away_team_draw_rate': away_stats.get('draw_rate', 0.3),\n",
    "            'team_strength_diff': home_stats.get('overall_win_rate', 0.4) - away_stats.get('overall_win_rate', 0.4),\n",
    "            'home_experience': min(home_stats.get('total_matches', 0) / 100, 1),\n",
    "            'away_experience': min(away_stats.get('total_matches', 0) / 100, 1)\n",
    "        })\n",
    "    \n",
    "    team_features = data.apply(get_team_features, axis=1)\n",
    "    return pd.concat([data, team_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53eb180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = add_team_features(data, team_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46fed42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved model training function\n",
    "def train_improved_model(X, y, use_smote=True, balance_classes=True):\n",
    "    \"\"\"Train model with various improvements\"\"\"\n",
    "    \n",
    "    # Handle class imbalance\n",
    "    if balance_classes:\n",
    "        # Calculate class weights\n",
    "        classes = np.unique(y)\n",
    "        class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
    "        class_weight_dict = dict(zip(classes, class_weights))\n",
    "        print(f\"Class weights: {class_weight_dict}\")\n",
    "    else:\n",
    "        class_weight_dict = None\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Apply SMOTE if requested\n",
    "    if use_smote:\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "        print(f\"Original training set: {len(X_train)}\")\n",
    "        print(f\"SMOTE balanced set: {len(X_train_balanced)}\")\n",
    "    else:\n",
    "        X_train_balanced, y_train_balanced = X_train, y_train\n",
    "    \n",
    "    # Model configurations to try\n",
    "    models = {\n",
    "        'HistGradientBoosting': HistGradientBoostingClassifier(\n",
    "            max_iter=300,\n",
    "            max_depth=6,\n",
    "            min_samples_leaf=10,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.2,\n",
    "            class_weight='balanced'\n",
    "        ),\n",
    "        'RandomForest': RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=8,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=5,\n",
    "            random_state=42,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_balanced, y_train_balanced, \n",
    "                                   cv=5, scoring='accuracy')\n",
    "        \n",
    "        # Train on full training set\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "        \n",
    "        # Test predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'test_predictions': y_pred,\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "            'classification_report': classification_report(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        print(f\"CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "        \n",
    "        if cv_scores.mean() > best_score:\n",
    "            best_score = cv_scores.mean()\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model, results, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cac1a070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {'Away': np.float64(1.0435779816513762), 'Draw': np.float64(1.4115822130299898), 'Home': np.float64(0.75)}\n",
      "Original training set: 3276\n",
      "SMOTE balanced set: 4368\n",
      "\n",
      "Training HistGradientBoosting...\n",
      "CV Score: 0.568 (+/- 0.111)\n",
      "\n",
      "Training RandomForest...\n",
      "CV Score: 0.554 (+/- 0.054)\n"
     ]
    }
   ],
   "source": [
    "# Define features (adjust based on what you want to include)\n",
    "feature_cols = [\n",
    "    'home_odds', 'draw_odds', 'away_odds',\n",
    "    'home_prob', 'draw_prob', 'away_prob', 'overround',\n",
    "    'home_away_odds_ratio', 'odds_spread', 'favorite_odds', 'underdog_odds',\n",
    "    'odds_variance', 'market_confidence', 'draw_bias', 'home_advantage',\n",
    "    'match_competitiveness', 'home_team_win_rate', 'away_team_win_rate',\n",
    "    'home_team_overall_rate', 'away_team_overall_rate', 'home_team_draw_rate',\n",
    "    'away_team_draw_rate', 'team_strength_diff', 'home_experience', 'away_experience'\n",
    "]\n",
    "    \n",
    "# Handle categorical features\n",
    "data_encoded = pd.get_dummies(data, columns=['home_odds_category', 'away_odds_category'])\n",
    "    \n",
    "X = data_encoded[feature_cols + [col for col in data_encoded.columns if 'odds_category' in col]]\n",
    "y = data['winning_outcome']\n",
    "\n",
    "best_model, results, X_test, y_test = train_improved_model(X, y, use_smote=True, balance_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72e95da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enhanced prediction function\n",
    "def predict_match_enhanced(model, team_stats, home_team, away_team, home_odds, draw_odds, away_odds):\n",
    "    \"\"\"Enhanced prediction with all new features\"\"\"\n",
    "    \n",
    "    # Create a temporary dataframe with the match\n",
    "    temp_data = pd.DataFrame({\n",
    "        'home_team': [home_team],\n",
    "        'away_team': [away_team],\n",
    "        'home_odds': [home_odds],\n",
    "        'draw_odds': [draw_odds],\n",
    "        'away_odds': [away_odds]\n",
    "    })\n",
    "    \n",
    "    # Add advanced features\n",
    "    temp_data = create_advanced_features(temp_data)\n",
    "    temp_data = add_team_features(temp_data, team_stats)\n",
    "    \n",
    "    # Select features (adjust based on your feature selection)\n",
    "    feature_cols = [\n",
    "        'home_odds', 'draw_odds', 'away_odds',\n",
    "        'home_prob', 'draw_prob', 'away_prob', 'overround',\n",
    "        'home_away_odds_ratio', 'odds_spread', 'favorite_odds', 'underdog_odds',\n",
    "        'odds_variance', 'market_confidence', 'draw_bias', 'home_advantage',\n",
    "        'match_competitiveness', 'home_team_win_rate', 'away_team_win_rate',\n",
    "        'home_team_overall_rate', 'away_team_overall_rate', 'home_team_draw_rate',\n",
    "        'away_team_draw_rate', 'team_strength_diff', 'home_experience', 'away_experience'\n",
    "    ]\n",
    "    \n",
    "    # Handle categorical features\n",
    "    categorical_cols = ['home_odds_category', 'away_odds_category']\n",
    "    temp_data_encoded = pd.get_dummies(temp_data, columns=categorical_cols, prefix=categorical_cols)\n",
    "    \n",
    "    # Ensure all feature columns exist\n",
    "    for col in feature_cols:\n",
    "        if col not in temp_data_encoded.columns:\n",
    "            temp_data_encoded[col] = 0\n",
    "    \n",
    "    # Add dummy categorical columns if they don't exist\n",
    "    for cat_col in categorical_cols:\n",
    "        for category in ['Heavy_Favorite', 'Favorite', 'Slight_Favorite', 'Underdog']:\n",
    "            dummy_col = f\"{cat_col}_{category}\"\n",
    "            if dummy_col not in temp_data_encoded.columns:\n",
    "                temp_data_encoded[dummy_col] = 0\n",
    "    \n",
    "    # Update feature list to include categorical dummies\n",
    "    all_features = feature_cols + [f\"{cat_col}_{cat}\" for cat_col in categorical_cols \n",
    "                                  for cat in ['Heavy_Favorite', 'Favorite', 'Slight_Favorite', 'Underdog']]\n",
    "    \n",
    "    X_pred = temp_data_encoded[all_features]\n",
    "    \n",
    "    # Get prediction and probabilities\n",
    "    prediction = model.predict(X_pred)[0]\n",
    "    probabilities = model.predict_proba(X_pred)[0]\n",
    "    \n",
    "    # Create probability dictionary\n",
    "    classes = model.classes_\n",
    "    prob_dict = {class_name: prob for class_name, prob in zip(classes, probabilities)}\n",
    "    \n",
    "    return prediction, prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb82f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted outcome: Draw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions on the test set\n",
    "home_team = \"Leeds\"\n",
    "away_team = \"Everton\"\n",
    "home_odds = 2.63\n",
    "draw_odds = 3.47\n",
    "away_odds = 2.80\n",
    "prediction, probs = predict_match_enhanced(best_model, team_stats, home_team, away_team, home_odds, draw_odds, away_odds)\n",
    "print(f\"Predicted outcome: {prediction}\")\n",
    "# print(f\"Probabilities: Home={probs[0]:.2f}, Draw={probs[1]:.2f}, Away={probs[2]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
